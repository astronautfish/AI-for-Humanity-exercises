{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "591e00d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test block, only used for quick testing.\n",
    "# Note that defined variables is inherited in other code blocks.\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([3,1,1,1])\n",
    "b = np.ones(3)\n",
    "c = np.column_stack((np.ones(4), a))\n",
    "\n",
    "c.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8da0e3-3010-434c-838b-70b22fcf68ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimates': array([ 1.04488458,  1.02109938, -1.04712233]),\n",
       " 'iterations': 5,\n",
       " 'converged': True}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "def test():\n",
    "    project_root = Path(__file__).resolve().parents[3]\n",
    "    relative_path = Path(__file__).resolve().relative_to(project_root)\n",
    "    print(f\"Hello from `{relative_path}` <3\")\n",
    "\n",
    "def sigmoid_function(z: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    return np.exp(z) / (1 + np.exp(z))\n",
    "\n",
    "\n",
    "\n",
    "def generat_logreg_data(\n",
    "        n: int,\n",
    "        beta: NDArray[np.float64],\n",
    "        seed: int = 0,\n",
    ") -> tuple[NDArray[np.float64], NDArray[np.int64]]:\n",
    "    \n",
    "    #1 Compute the number of covariates from the length of the beta vector\n",
    "    beta_len = beta.shape[0] - 1 # has to be -1, else the intercept is included (generated with matrix_ones)\n",
    "    \n",
    "    #2 Create a random number generator called 'rng'\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    #3 Simulate a matrix X with shape (N, p+1).\n",
    "        #3.1 First column is all 1.\n",
    "    matrix_ones = np.ones(n)\n",
    "        #3.2 The others are drawn from a uniform dist ~Unif(-1,1)\n",
    "    matrix_X_draw_uniform = rng.integers(low=-1, high=2, size=(n,beta_len))\n",
    "\n",
    "    X = np.column_stack((matrix_ones, matrix_X_draw_uniform))\n",
    "        \n",
    "    #4 Draw y by using rng.binomial with n=1 and prob param = p (not num of covariates)\n",
    "    z = X @ beta\n",
    "    p = sigmoid_function(z)\n",
    "    y = rng.binomial(1, p)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def irls(\n",
    "    X: NDArray[np.float64],\n",
    "    y: NDArray[np.int64],\n",
    "    tol: float = 1e-8, # Tolerance. See stop condition\n",
    "    max_iter: int = 100,\n",
    "):\n",
    "    \"\"\"Iteratively reweighted least squares solver.\"\"\"\n",
    "    n, p = X.shape # amount of draws and covariates.\n",
    "    converged = False # convergence flag\n",
    "    y = y.reshape(-1,1).astype(np.float64) # Make 'y' a column vector\n",
    "    beta = np.ones([p, 1]) # see comment about initialising beta as X.shape[0]\n",
    "    #print(beta)\n",
    "\n",
    "    \n",
    "    for t in range(0,max_iter):\n",
    "\n",
    "        # compute probability\n",
    "        p_hat = sigmoid_function(X @ beta)\n",
    "\n",
    "        # Weights from the diagonal\n",
    "        W = (p_hat * (1-p_hat))\n",
    "\n",
    "        # Calculate Z\n",
    "        Z = X @ beta + (y - p_hat) / W\n",
    "\n",
    "        # Apply weights\n",
    "        WX = X * W\n",
    "        # Do the New \n",
    "        beta_next = np.linalg.inv(X.T @ WX) @ (X.T @ (W * Z))\n",
    "\n",
    "        # Stop condition. \n",
    "        if np.any(np.abs(beta_next - beta) < tol):\n",
    "            \"\"\"\n",
    "            Why is the original \"(beta_next - beta) > tol\", when we clearly are checking if its below the tolerance?\n",
    "            Else we have to include a not in the \"if\" statement -> its confusing\n",
    "            \"\"\"\n",
    "            converged = True\n",
    "            beta = beta_next\n",
    "            break\n",
    "\n",
    "        beta = beta_next\n",
    "        \n",
    "    return {\n",
    "        \"estimates\": beta.flatten(),\n",
    "        \"iterations\": t,\n",
    "        \"converged\": converged\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Check whether the algorithm converged each iteration\n",
    "        # Max iterations is set to 100\n",
    "    # Return a dictionary with 'estimates, iterations and converged'\n",
    "        # Estimates as a 1d numpy array shape (p+1)\n",
    "        # Iterations = the number of iterations until converd\n",
    "        # Converged = True flag if <= 100, else false\n",
    "    \"\"\" # Initialize beta to (X.shape[0],1) column vector.\n",
    "    What? X.shape[0], 1 is a (n,1) -> X.shape gives a (n,p)\n",
    "    Shouldn't it be (p,1) column vector? Works if it's p, also makes sense since we feed beta in generat_logreg_data with a 3x1 array.\n",
    "    Also, what\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = generat_logreg_data(10000, np.array([1,1,-1]), seed = 1999)\n",
    "irls(X,y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
